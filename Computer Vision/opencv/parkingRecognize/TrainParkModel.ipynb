{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense, Flatten, Dropout, Lambda, Input\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import resnet50\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "KTF.set_session(tf.Session(config=tf.ConfigProto(device_count={'gpu':0})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count= 381\n",
      "valid count= 164\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "trainCount = 0\n",
    "validCount = 0\n",
    "\n",
    "\n",
    "trainFolder = 'train_data/train'\n",
    "for sub_folder in os.listdir(trainFolder):\n",
    "    path, dirs, files = next(os.walk(os.path.join(trainFolder,sub_folder)))\n",
    "    trainCount += len(files)\n",
    "\n",
    "\n",
    "validFolder = 'train_data/test'\n",
    "for sub_folder in os.listdir(validFolder):\n",
    "    path, dirs, files = next(os.walk(os.path.join(validFolder,sub_folder)))\n",
    "    validCount += len(files)\n",
    "    \n",
    "print(\"train count=\", trainCount)\n",
    "print('valid count=', validCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape = (48, 48, 3))\n",
    "x = Lambda(resnet50.preprocess_input)(input_img)\n",
    "ResNet50_model = ResNet50(input_tensor = x, weights = 'imagenet', include_top = False)\n",
    "ResNet50_model.trainable = False;\n",
    "x = Flatten()( ResNet50_model.output)\n",
    "predictions = Dense(2, activation=\"softmax\")(x)\n",
    "finalModel = Model(input = ResNet50_model.input, output = predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalModel.compile(loss = 'binary_crossentropy',\n",
    "                          optimizer = 'Adam',\n",
    "                          metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 images belonging to 2 classes.\n",
      "Found 164 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "height, width = 48, 48\n",
    "batchSize = 32\n",
    "train_datagen = ImageDataGenerator(\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.1,\n",
    "width_shift_range = 0.1,\n",
    "height_shift_range=0.1,\n",
    "rotation_range=5)\n",
    "\n",
    "valid_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "trainFolder,\n",
    "target_size = (height, width),\n",
    "batch_size = batchSize,\n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "validFolder,\n",
    "target_size = (height, width),\n",
    "batch_size = batchSize,\n",
    "class_mode = \"categorical\")\n",
    "\n",
    "checkpointer = ModelCheckpoint(\"parking.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 37s 3s/step - loss: 0.2117 - acc: 0.9261 - val_loss: 2.4890 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83125, saving model to parking.h5\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 2s 203ms/step - loss: 0.1390 - acc: 0.9656 - val_loss: 1.1832 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.83125 to 0.92424, saving model to parking.h5\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 2s 146ms/step - loss: 0.1503 - acc: 0.9741 - val_loss: 0.7287 - val_acc: 0.9545\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92424 to 0.95455, saving model to parking.h5\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 0.0335 - acc: 0.9915 - val_loss: 0.6453 - val_acc: 0.9545\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95455\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 1s 136ms/step - loss: 0.1029 - acc: 0.9886 - val_loss: 1.2714 - val_acc: 0.9091\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95455\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 2s 137ms/step - loss: 0.0334 - acc: 0.9943 - val_loss: 1.0802 - val_acc: 0.9167\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95455\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 1s 136ms/step - loss: 0.0691 - acc: 0.9915 - val_loss: 0.5571 - val_acc: 0.9313\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95455\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 2s 137ms/step - loss: 0.0965 - acc: 0.9943 - val_loss: 0.1500 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.95455 to 0.97727, saving model to parking.h5\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 2s 140ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1855 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.97727\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 0.0166 - acc: 0.9969 - val_loss: 0.1750 - val_acc: 0.9621\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.97727\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 2s 140ms/step - loss: 0.0510 - acc: 0.9858 - val_loss: 0.2429 - val_acc: 0.9545\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.97727\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 1s 136ms/step - loss: 0.0185 - acc: 0.9972 - val_loss: 0.1218 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.97727\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 1s 135ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0870 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.97727 to 0.98125, saving model to parking.h5\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 2s 140ms/step - loss: 0.0998 - acc: 0.9829 - val_loss: 0.9925 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98125\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 0.1503 - acc: 0.9773 - val_loss: 0.2483 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98125\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 2s 137ms/step - loss: 0.0216 - acc: 0.9915 - val_loss: 0.0798 - val_acc: 0.9848\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.98125 to 0.98485, saving model to parking.h5\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 1s 136ms/step - loss: 0.0635 - acc: 0.9858 - val_loss: 0.3445 - val_acc: 0.9697\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.98485\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.98485 to 0.99242, saving model to parking.h5\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 1s 135ms/step - loss: 0.0533 - acc: 0.9943 - val_loss: 0.0958 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99242\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 1s 136ms/step - loss: 0.0317 - acc: 0.9915 - val_loss: 0.0663 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2558f341588>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalModel.fit_generator(\n",
    "    train_generator,\n",
    "    epochs = 20,\n",
    "    steps_per_epoch = trainCount // batchSize,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validCount // batchSize,\n",
    "    verbose = 1,\n",
    "    callbacks = [checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "def path_to_tensor(imgPath):\n",
    "    img = image.load_img(imgPath, target_size=(48, 48))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'empty': 0, 'occupied': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.995\n"
     ]
    }
   ],
   "source": [
    "pred_result = finalModel.predict(path_to_tensor('./cnn_data/spot359.jpg'))\n",
    "pred_result = pred_result.clip(min=0.005, max=0.995)\n",
    "index = np.argmax(pred_result[0])\n",
    "print(index)\n",
    "print(pred_result[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.99999905\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
